{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Adversarial Attack (Cifar Challenge).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadzavvari/Adversarial-Training-on-CIFAR10/blob/master/Adversarial_Attack_(Cifar_Challenge).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_22Oo-Kv3zLw",
        "colab_type": "text"
      },
      "source": [
        "**IN THE NAME OF GOD**\n",
        "\n",
        "In this notebook, we are going to attack the neural network which has been adversarialy trained by MadryLab. The dataset is Cifar10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ak5nXS_3sCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wb8gMrYn_3o8",
        "colab_type": "text"
      },
      "source": [
        "Here we are loading the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccEBpNEk_ssv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4c004b3e-beaa-49bb-c60a-4da0e01bb86c"
      },
      "source": [
        "cifar_train = datasets.CIFAR10(\"../data\", train=True, download=True, transform=transforms.ToTensor())\n",
        "cifar_test = datasets.CIFAR10(\"../data\", train=False, download=True, transform=transforms.ToTensor())\n",
        "train_loader = DataLoader(cifar_train, batch_size = 100, shuffle=True)\n",
        "test_loader = DataLoader(cifar_test, batch_size = 100, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RacHJHTC7P5_",
        "colab_type": "text"
      },
      "source": [
        "Now we load the pre-trained model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICie92T47N2S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "1fd32947-d6b2-4f29-85f7-63cb12f8579e"
      },
      "source": [
        "\"\"\"Downloads a model, computes its SHA256 hash and unzips it\n",
        "   at the proper location.\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import sys\n",
        "import zipfile\n",
        "import hashlib\n",
        "\n",
        "\n",
        "url = 'https://www.dropbox.com/s/g4b6ntrp8zrudbz/adv_trained.zip?dl=1'\n",
        "\n",
        "fname = url.split('/')[-1].split('?')[0]  # get the name of the file\n",
        "\n",
        "# model download\n",
        "print('Downloading models')\n",
        "if sys.version_info >= (3,):\n",
        "  import urllib.request\n",
        "  urllib.request.urlretrieve(url, fname)\n",
        "else:\n",
        "  import urllib\n",
        "  urllib.urlretrieve(url, fname)\n",
        "\n",
        "# computing model hash\n",
        "sha256 = hashlib.sha256()\n",
        "with open(fname, 'rb') as f:\n",
        "  data = f.read()\n",
        "  sha256.update(data)\n",
        "print('SHA256 hash: {}'.format(sha256.hexdigest()))\n",
        "\n",
        "# extracting model\n",
        "print('Extracting model')\n",
        "with zipfile.ZipFile(fname, 'r') as model_zip:\n",
        "  model_zip.extractall()\n",
        "  print('Extracted model in {}'.format(model_zip.namelist()[0]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading models\n",
            "SHA256 hash: 996384ac78ec749673e43cb823b9fb837a4da8d529ed2ef98e8d94053529fa5d\n",
            "Extracting model\n",
            "Extracted model in models/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YfgdOrk9pY9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "39b18217-015d-4c83-814b-4792fd736bc6"
      },
      "source": [
        "# based on https://github.com/tensorflow/models/tree/master/resnet\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "class Model(object):\n",
        "  \"\"\"ResNet model.\"\"\"\n",
        "\n",
        "  def __init__(self, mode):\n",
        "    \"\"\"ResNet constructor.\n",
        "    Args:\n",
        "      mode: One of 'train' and 'eval'.\n",
        "    \"\"\"\n",
        "    self.mode = mode\n",
        "    self._build_model()\n",
        "\n",
        "  def add_internal_summaries(self):\n",
        "    pass\n",
        "\n",
        "  def _stride_arr(self, stride):\n",
        "    \"\"\"Map a stride scalar to the stride array for tf.nn.conv2d.\"\"\"\n",
        "    return [1, stride, stride, 1]\n",
        "\n",
        "  def _build_model(self):\n",
        "    assert self.mode == 'train' or self.mode == 'eval'\n",
        "    \"\"\"Build the core model within the graph.\"\"\"\n",
        "    with tf.variable_scope('input'):\n",
        "\n",
        "      self.x_input = tf.placeholder(\n",
        "        tf.float32,\n",
        "        shape=[None, 32, 32, 3])\n",
        "\n",
        "      self.y_input = tf.placeholder(tf.int64, shape=None)\n",
        "\n",
        "\n",
        "      input_standardized = tf.map_fn(lambda img: tf.image.per_image_standardization(img),\n",
        "                               self.x_input)\n",
        "      x = self._conv('init_conv', input_standardized, 3, 3, 16, self._stride_arr(1))\n",
        "\n",
        "\n",
        "\n",
        "    strides = [1, 2, 2]\n",
        "    activate_before_residual = [True, False, False]\n",
        "    res_func = self._residual\n",
        "\n",
        "    # w28-10 wide residual network (https://arxiv.org/abs/1605.07146v1)\n",
        "    # use filters = [16, 16, 32, 64] for a non-wide version\n",
        "    filters = [16, 160, 320, 640]\n",
        "\n",
        "\n",
        "    # Update hps.num_residual_units to 9\n",
        "\n",
        "    with tf.variable_scope('unit_1_0'):\n",
        "      x = res_func(x, filters[0], filters[1], self._stride_arr(strides[0]),\n",
        "                   activate_before_residual[0])\n",
        "    for i in range(1, 5):\n",
        "      with tf.variable_scope('unit_1_%d' % i):\n",
        "        x = res_func(x, filters[1], filters[1], self._stride_arr(1), False)\n",
        "\n",
        "    with tf.variable_scope('unit_2_0'):\n",
        "      x = res_func(x, filters[1], filters[2], self._stride_arr(strides[1]),\n",
        "                   activate_before_residual[1])\n",
        "    for i in range(1, 5):\n",
        "      with tf.variable_scope('unit_2_%d' % i):\n",
        "        x = res_func(x, filters[2], filters[2], self._stride_arr(1), False)\n",
        "\n",
        "    with tf.variable_scope('unit_3_0'):\n",
        "      x = res_func(x, filters[2], filters[3], self._stride_arr(strides[2]),\n",
        "                   activate_before_residual[2])\n",
        "    for i in range(1, 5):\n",
        "      with tf.variable_scope('unit_3_%d' % i):\n",
        "        x = res_func(x, filters[3], filters[3], self._stride_arr(1), False)\n",
        "\n",
        "    with tf.variable_scope('unit_last'):\n",
        "      x = self._batch_norm('final_bn', x)\n",
        "      x = self._relu(x, 0.1)\n",
        "      x = self._global_avg_pool(x)\n",
        "\n",
        "    with tf.variable_scope('logit'):\n",
        "      self.pre_softmax = self._fully_connected(x, 10)\n",
        "\n",
        "    self.predictions = tf.argmax(self.pre_softmax, 1)\n",
        "    self.correct_prediction = tf.equal(self.predictions, self.y_input)\n",
        "    self.num_correct = tf.reduce_sum(\n",
        "        tf.cast(self.correct_prediction, tf.int64))\n",
        "    self.accuracy = tf.reduce_mean(\n",
        "        tf.cast(self.correct_prediction, tf.float32))\n",
        "\n",
        "    with tf.variable_scope('costs'):\n",
        "      self.y_xent = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "          logits=self.pre_softmax, labels=self.y_input)\n",
        "      self.xent = tf.reduce_sum(self.y_xent, name='y_xent')\n",
        "      self.mean_xent = tf.reduce_mean(self.y_xent)\n",
        "      self.weight_decay_loss = self._decay()\n",
        "\n",
        "  def _batch_norm(self, name, x):\n",
        "    \"\"\"Batch normalization.\"\"\"\n",
        "    with tf.name_scope(name):\n",
        "      return tf.contrib.layers.batch_norm(\n",
        "          inputs=x,\n",
        "          decay=.9,\n",
        "          center=True,\n",
        "          scale=True,\n",
        "          activation_fn=None,\n",
        "          updates_collections=None,\n",
        "          is_training=(self.mode == 'train'))\n",
        "\n",
        "  def _residual(self, x, in_filter, out_filter, stride,\n",
        "                activate_before_residual=False):\n",
        "    \"\"\"Residual unit with 2 sub layers.\"\"\"\n",
        "    if activate_before_residual:\n",
        "      with tf.variable_scope('shared_activation'):\n",
        "        x = self._batch_norm('init_bn', x)\n",
        "        x = self._relu(x, 0.1)\n",
        "        orig_x = x\n",
        "    else:\n",
        "      with tf.variable_scope('residual_only_activation'):\n",
        "        orig_x = x\n",
        "        x = self._batch_norm('init_bn', x)\n",
        "        x = self._relu(x, 0.1)\n",
        "\n",
        "    with tf.variable_scope('sub1'):\n",
        "      x = self._conv('conv1', x, 3, in_filter, out_filter, stride)\n",
        "\n",
        "    with tf.variable_scope('sub2'):\n",
        "      x = self._batch_norm('bn2', x)\n",
        "      x = self._relu(x, 0.1)\n",
        "      x = self._conv('conv2', x, 3, out_filter, out_filter, [1, 1, 1, 1])\n",
        "\n",
        "    with tf.variable_scope('sub_add'):\n",
        "      if in_filter != out_filter:\n",
        "        orig_x = tf.nn.avg_pool(orig_x, stride, stride, 'VALID')\n",
        "        orig_x = tf.pad(\n",
        "            orig_x, [[0, 0], [0, 0], [0, 0],\n",
        "                     [(out_filter-in_filter)//2, (out_filter-in_filter)//2]])\n",
        "      x += orig_x\n",
        "\n",
        "    tf.logging.debug('image after unit %s', x.get_shape())\n",
        "    return x\n",
        "\n",
        "  def _decay(self):\n",
        "    \"\"\"L2 weight decay loss.\"\"\"\n",
        "    costs = []\n",
        "    for var in tf.trainable_variables():\n",
        "      if var.op.name.find('DW') > 0:\n",
        "        costs.append(tf.nn.l2_loss(var))\n",
        "    return tf.add_n(costs)\n",
        "\n",
        "  def _conv(self, name, x, filter_size, in_filters, out_filters, strides):\n",
        "    \"\"\"Convolution.\"\"\"\n",
        "    with tf.variable_scope(name):\n",
        "      n = filter_size * filter_size * out_filters\n",
        "      kernel = tf.get_variable(\n",
        "          'DW', [filter_size, filter_size, in_filters, out_filters],\n",
        "          tf.float32, initializer=tf.random_normal_initializer(\n",
        "              stddev=np.sqrt(2.0/n)))\n",
        "      return tf.nn.conv2d(x, kernel, strides, padding='SAME')\n",
        "\n",
        "  def _relu(self, x, leakiness=0.0):\n",
        "    \"\"\"Relu, with optional leaky support.\"\"\"\n",
        "    return tf.where(tf.less(x, 0.0), leakiness * x, x, name='leaky_relu')\n",
        "\n",
        "  def _fully_connected(self, x, out_dim):\n",
        "    \"\"\"FullyConnected layer for final output.\"\"\"\n",
        "    num_non_batch_dimensions = len(x.shape)\n",
        "    prod_non_batch_dimensions = 1\n",
        "    for ii in range(num_non_batch_dimensions - 1):\n",
        "      prod_non_batch_dimensions *= int(x.shape[ii + 1])\n",
        "    x = tf.reshape(x, [tf.shape(x)[0], -1])\n",
        "    w = tf.get_variable(\n",
        "        'DW', [prod_non_batch_dimensions, out_dim],\n",
        "        initializer=tf.uniform_unit_scaling_initializer(factor=1.0))\n",
        "    b = tf.get_variable('biases', [out_dim],\n",
        "                        initializer=tf.constant_initializer())\n",
        "    return tf.nn.xw_plus_b(x, w, b)\n",
        "\n",
        "  def _global_avg_pool(self, x):\n",
        "    assert x.get_shape().ndims == 4\n",
        "    return tf.reduce_mean(x, [1, 2])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2fkXV289PPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import sys\n",
        "import math\n",
        "with open('/content/models/adv_trained/config.json') as config_file:\n",
        "  config = json.load(config_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpIBs2N5-Sq9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "b863d95c-2710-439e-c781-fe0ff1096ba5"
      },
      "source": [
        "model_trained = Model(mode='eval')\n",
        "print(model_trained)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/image_ops_impl.py:1518: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-5-e1dae8c6d56b>:163: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py:507: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
            "<__main__.Model object at 0x7f57524dd630>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "larqfi4fuUUl",
        "colab_type": "text"
      },
      "source": [
        "The PGD optimizer (in the other word: \"THE ATTACER\"):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpv-Em_TpcY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pgd_linf(model, X, y, epsilon=0.1, alpha=0.01, num_iter=20, randomize=False):\n",
        "    \"\"\" Construct FGSM adversarial examples on the examples X\"\"\"\n",
        "    if randomize:\n",
        "        delta = torch.rand_like(X, requires_grad=True)\n",
        "        delta.data = delta.data * 2 * epsilon - epsilon\n",
        "    else:\n",
        "        delta = torch.zeros_like(X, requires_grad=True)\n",
        "        \n",
        "    for t in range(num_iter):\n",
        "        loss = nn.CrossEntropyLoss()(model(X + delta), y)\n",
        "        loss.backward()\n",
        "        delta.data = (delta + alpha*delta.grad.detach().sign()).clamp(-epsilon,epsilon)\n",
        "        delta.grad.zero_()\n",
        "    return delta.detach()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYuHBwQ5upWn",
        "colab_type": "text"
      },
      "source": [
        "Task of each epoch in adversarial training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ_AVwkTpwxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_adversarial(loader, model, opt=None, **kwargs):\n",
        "    \"\"\"Adversarial training/evaluation epoch over the dataset\"\"\"\n",
        "    total_loss, total_err = 0.,0.\n",
        "    for X,y in loader:\n",
        "        X,y = X.to(device), y.to(device)\n",
        "        delta = pgd_linf(model, X, y, **kwargs)\n",
        "        yp = model(X+delta)\n",
        "        loss = nn.CrossEntropyLoss()(yp,y)\n",
        "        if opt:\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        \n",
        "        total_err += (yp.max(dim=1)[1] != y).sum().item()\n",
        "        total_loss += loss.item() * X.shape[0]\n",
        "    return total_err / len(loader.dataset), total_loss / len(loader.dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS7Mipt5_T04",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "e03080e1-3ec5-49ef-8f61-aea54a0031ad"
      },
      "source": [
        "for t in range(2):\n",
        "    adv_err, adv_loss = epoch_adversarial(test_loader, model_trained)\n",
        "    if t == 4:\n",
        "        for param_group in opt.param_groups:\n",
        "            param_group[\"lr\"] = 1e-2\n",
        "    print(*(\"{:.6f}\".format(i) for i in (adv_err)))\n",
        "torch.save(model_cnn_robust.state_dict(), \"model_trained.pt\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-ed2a6d42fa6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0madv_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_adversarial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_trained\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mparam_group\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-e2efb48061f9>\u001b[0m in \u001b[0;36mepoch_adversarial\u001b[0;34m(loader, model, opt, **kwargs)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpgd_linf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0myp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-f7fa4138d98f>\u001b[0m in \u001b[0;36mpgd_linf\u001b[0;34m(model, X, y, epsilon, alpha, num_iter, randomize)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'Model' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOEzwJhf_mJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}