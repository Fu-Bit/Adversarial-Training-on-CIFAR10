{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Adversarial Training.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadzavvari/Adversarial-Training-on-CIFAR10/blob/master/Adversarial_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRT76yxcteE2",
        "colab_type": "text"
      },
      "source": [
        "**IN THE NAME OF GOD**\n",
        "\n",
        "In this notebook, we are going to train a robust neural network against the L_infinity attacks using adversarial training with PGD optimization. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-19DWZWNMQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXf_7Lk6uRJ7",
        "colab_type": "text"
      },
      "source": [
        "Loading data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6SfEYs8Ny6m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2f7b586a-ea50-459b-b5bf-1f336703121e"
      },
      "source": [
        "cifar_train = datasets.CIFAR10(\"../data\", train=True, download=True, transform=transforms.ToTensor())\n",
        "cifar_test = datasets.CIFAR10(\"../data\", train=False, download=True, transform=transforms.ToTensor())\n",
        "train_loader = DataLoader(cifar_train, batch_size = 100, shuffle=True)\n",
        "test_loader = DataLoader(cifar_test, batch_size = 100, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk3ySxHOu_Oi",
        "colab_type": "text"
      },
      "source": [
        "The code of the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hgKJKOqNzo4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.shape[0], -1) \n",
        "\n",
        "model_cnn = nn.Sequential(nn.Conv2d(3, 32, 3), nn.ReLU(),\n",
        "                          nn.Conv2d(32, 32, 3, padding=1, stride=2), nn.ReLU(),\n",
        "                          nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n",
        "                          nn.Conv2d(64, 64, 3, padding=1, stride=2), nn.ReLU(),\n",
        "                          Flatten(),\n",
        "                          nn.Linear(8*8*64, 100), nn.ReLU(),\n",
        "                          nn.Linear(100, 10)).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKVo03xyudXG",
        "colab_type": "text"
      },
      "source": [
        "Epochs to train the \"standard\" CNN:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNA8IEXRpjsb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch(loader, model, opt=None):\n",
        "    \"\"\"Standard training/evaluation epoch over the dataset\"\"\"\n",
        "    total_loss, total_err = 0.,0.\n",
        "    for X,y in loader:\n",
        "        X,y = X.to(device), y.to(device)\n",
        "        yp = model(X)\n",
        "        loss = nn.CrossEntropyLoss()(yp,y)\n",
        "        if opt:\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        \n",
        "        total_err += (yp.max(dim=1)[1] != y).sum().item()\n",
        "        total_loss += loss.item() * X.shape[0]\n",
        "    return total_err / len(loader.dataset), total_loss / len(loader.dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYuHBwQ5upWn",
        "colab_type": "text"
      },
      "source": [
        "Task of each epoch in adversarial training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ_AVwkTpwxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_adversarial(loader, model, opt=None, **kwargs):\n",
        "    \"\"\"Adversarial training/evaluation epoch over the dataset\"\"\"\n",
        "    total_loss, total_err = 0.,0.\n",
        "    for X,y in loader:\n",
        "        X,y = X.to(device), y.to(device)\n",
        "        delta = pgd_linf(model, X, y, **kwargs)\n",
        "        yp = model(X+delta)\n",
        "        loss = nn.CrossEntropyLoss()(yp,y)\n",
        "        if opt:\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        \n",
        "        total_err += (yp.max(dim=1)[1] != y).sum().item()\n",
        "        total_loss += loss.item() * X.shape[0]\n",
        "    return total_err / len(loader.dataset), total_loss / len(loader.dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "larqfi4fuUUl",
        "colab_type": "text"
      },
      "source": [
        "The PGD optimizer (in the other word: \"THE ATTACER\"):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpv-Em_TpcY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pgd_linf(model, X, y, epsilon=0.1, alpha=0.01, num_iter=20, randomize=False):\n",
        "    \"\"\" Construct FGSM adversarial examples on the examples X\"\"\"\n",
        "    if randomize:\n",
        "        delta = torch.rand_like(X, requires_grad=True)\n",
        "        delta.data = delta.data * 2 * epsilon - epsilon\n",
        "    else:\n",
        "        delta = torch.zeros_like(X, requires_grad=True)\n",
        "        \n",
        "    for t in range(num_iter):\n",
        "        loss = nn.CrossEntropyLoss()(model(X + delta), y)\n",
        "        loss.backward()\n",
        "        delta.data = (delta + alpha*delta.grad.detach().sign()).clamp(-epsilon,epsilon)\n",
        "        delta.grad.zero_()\n",
        "    return delta.detach()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEIg-xUvuyYX",
        "colab_type": "text"
      },
      "source": [
        "Train the model which is not robust:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq9Nwuewp1Iy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "d67d917e-9ea5-4c94-99c8-3db2f0c09feb"
      },
      "source": [
        "opt = optim.SGD(model_cnn.parameters(), lr=1e-1)\n",
        "for t in range(10):\n",
        "    train_err, train_loss = epoch(train_loader, model_cnn, opt)\n",
        "    test_err, test_loss = epoch(test_loader, model_cnn)\n",
        "    adv_err, adv_loss = epoch_adversarial(test_loader, model_cnn)\n",
        "    if t == 4:\n",
        "        for param_group in opt.param_groups:\n",
        "            param_group[\"lr\"] = 1e-2\n",
        "    print(*(\"{:.6f}\".format(i) for i in (train_err, test_err, adv_err)), sep=\"\\t\")\n",
        "torch.save(model_cnn.state_dict(), \"model_cnn.pt\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-aa1e23d78e3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtest_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_cnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0madv_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_adversarial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_cnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-e9a5c5bcd0dd>\u001b[0m in \u001b[0;36mepoch\u001b[0;34m(loader, model, opt)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8jCZh1aySHF",
        "colab_type": "text"
      },
      "source": [
        "As you can see the error of the network when we test it with adversarial exampls is very high: 100% => We need to train a network which can be strong against these examples.\n",
        "Now we make the new model which has the same architecture as the previous model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eToxbl9Pp4r6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_cnn_robust = nn.Sequential(nn.Conv2d(3, 32, 3), nn.ReLU(),\n",
        "                                 nn.Conv2d(32, 32, 3, padding=1, stride=2), nn.ReLU(),\n",
        "                                 nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n",
        "                                 nn.Conv2d(64, 64, 3, padding=1, stride=2), nn.ReLU(),\n",
        "                                 Flatten(),\n",
        "                                 nn.Linear(8*8*64, 100), nn.ReLU(),\n",
        "                                 nn.Linear(100, 10)).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_j11i_nz1Sr",
        "colab_type": "text"
      },
      "source": [
        "This time we use epoch_adversarial to train the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz5IYQmJz1Bw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = optim.SGD(model_cnn_robust.parameters(), lr=1e-1)\n",
        "for t in range(2):\n",
        "    train_err, train_loss = epoch_adversarial(train_loader, model_cnn_robust, opt)\n",
        "    test_err, test_loss = epoch(test_loader, model_cnn_robust)\n",
        "    adv_err, adv_loss = epoch_adversarial(test_loader, model_cnn_robust)\n",
        "    if t == 4:\n",
        "        for param_group in opt.param_groups:\n",
        "            param_group[\"lr\"] = 1e-2\n",
        "    print(*(\"{:.6f}\".format(i) for i in (train_err, test_err, adv_err)), sep=\"\\t\")\n",
        "torch.save(model_cnn_robust.state_dict(), \"model_cnn_robust.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjbbJu8K5LQK",
        "colab_type": "text"
      },
      "source": [
        "As you can see, in this case the error of the model against adversarial examples is: %."
      ]
    }
  ]
}