{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Adversarial Training.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadzavvari/Adversarial-Training-on-CIFAR10/blob/master/Adversarial_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRT76yxcteE2",
        "colab_type": "text"
      },
      "source": [
        "**IN THE NAME OF GOD**\n",
        "\n",
        "In this notebook, we are going to train a robust neural network against the L_infinity attacks using adversarial training with PGD optimization. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-19DWZWNMQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXf_7Lk6uRJ7",
        "colab_type": "text"
      },
      "source": [
        "Loading data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6SfEYs8Ny6m",
        "colab_type": "code",
        "outputId": "a864080f-b6e8-405f-91bb-47b1e98117fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "cifar_train = datasets.CIFAR10(\"../data\", train=True, download=True, transform=transforms.ToTensor())\n",
        "cifar_test = datasets.CIFAR10(\"../data\", train=False, download=True, transform=transforms.ToTensor())\n",
        "train_loader = DataLoader(cifar_train, batch_size = 100, shuffle=True)\n",
        "test_loader = DataLoader(cifar_test, batch_size = 100, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 169074688/170498071 [00:12<00:00, 15336953.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/cifar-10-python.tar.gz to ../data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk3ySxHOu_Oi",
        "colab_type": "text"
      },
      "source": [
        "The code of the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hgKJKOqNzo4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.shape[0], -1) \n",
        "\n",
        "model_cnn = nn.Sequential(nn.Conv2d(3, 32, 3), nn.ReLU(),\n",
        "                          nn.Conv2d(32, 32, 3, padding=1, stride=2), nn.ReLU(),\n",
        "                          nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n",
        "                          nn.Conv2d(64, 64, 3, padding=1, stride=2), nn.ReLU(),\n",
        "                          Flatten(),\n",
        "                          nn.Linear(8*8*64, 100), nn.ReLU(),\n",
        "                          nn.Linear(100, 10)).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKVo03xyudXG",
        "colab_type": "text"
      },
      "source": [
        "Epochs to train the \"standard\" CNN:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNA8IEXRpjsb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch(loader, model, opt=None):\n",
        "    \"\"\"Standard training/evaluation epoch over the dataset\"\"\"\n",
        "    total_loss, total_err = 0.,0.\n",
        "    for X,y in loader:\n",
        "        X,y = X.to(device), y.to(device)\n",
        "        yp = model(X)\n",
        "        loss = nn.CrossEntropyLoss()(yp,y)\n",
        "        if opt:\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        \n",
        "        total_err += (yp.max(dim=1)[1] != y).sum().item()\n",
        "        total_loss += loss.item() * X.shape[0]\n",
        "    return total_err / len(loader.dataset), total_loss / len(loader.dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYuHBwQ5upWn",
        "colab_type": "text"
      },
      "source": [
        "Task of each epoch in adversarial training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ_AVwkTpwxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_adversarial(loader, model, opt=None, **kwargs):\n",
        "    \"\"\"Adversarial training/evaluation epoch over the dataset\"\"\"\n",
        "    total_loss, total_err = 0.,0.\n",
        "    for X,y in loader:\n",
        "        X,y = X.to(device), y.to(device)\n",
        "        delta = pgd_linf(model, X, y, **kwargs)\n",
        "        yp = model(X+delta)\n",
        "        loss = nn.CrossEntropyLoss()(yp,y)\n",
        "        if opt:\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        \n",
        "        total_err += (yp.max(dim=1)[1] != y).sum().item()\n",
        "        total_loss += loss.item() * X.shape[0]\n",
        "    return total_err / len(loader.dataset), total_loss / len(loader.dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "larqfi4fuUUl",
        "colab_type": "text"
      },
      "source": [
        "The PGD optimizer (in the other word: \"THE ATTACER\"):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpv-Em_TpcY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pgd_linf(model, X, y, epsilon=0.1, alpha=0.01, num_iter=20, randomize=False):\n",
        "    \"\"\" Construct FGSM adversarial examples on the examples X\"\"\"\n",
        "    if randomize:\n",
        "        delta = torch.rand_like(X, requires_grad=True)\n",
        "        delta.data = delta.data * 2 * epsilon - epsilon\n",
        "    else:\n",
        "        delta = torch.zeros_like(X, requires_grad=True)\n",
        "        \n",
        "    for t in range(num_iter):\n",
        "        loss = nn.CrossEntropyLoss()(model(X + delta), y)\n",
        "        loss.backward()\n",
        "        delta.data = (delta + alpha*delta.grad.detach().sign()).clamp(-epsilon,epsilon)\n",
        "        delta.grad.zero_()\n",
        "    return delta.detach()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEIg-xUvuyYX",
        "colab_type": "text"
      },
      "source": [
        "Train the model which is not robust:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq9Nwuewp1Iy",
        "colab_type": "code",
        "outputId": "e5470784-e7d3-4c3c-aa67-4a33f62a4f74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "opt = optim.SGD(model_cnn.parameters(), lr=1e-1)\n",
        "for t in range(10):\n",
        "    train_err, train_loss = epoch(train_loader, model_cnn, opt)\n",
        "    test_err, test_loss = epoch(test_loader, model_cnn)\n",
        "    adv_err, adv_loss = epoch_adversarial(test_loader, model_cnn)\n",
        "    if t == 4:\n",
        "        for param_group in opt.param_groups:\n",
        "            param_group[\"lr\"] = 1e-2\n",
        "    print(*(\"{:.6f}\".format(i) for i in (train_err, test_err, adv_err)), sep=\"\\t\")\n",
        "torch.save(model_cnn.state_dict(), \"model_cnn.pt\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r170500096it [00:29, 15336953.33it/s]                               "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.782700\t0.677600\t0.977700\n",
            "0.630500\t0.621700\t0.999800\n",
            "0.529680\t0.478600\t1.000000\n",
            "0.468760\t0.450200\t1.000000\n",
            "0.418320\t0.415700\t1.000000\n",
            "0.340140\t0.388200\t1.000000\n",
            "0.324620\t0.385800\t1.000000\n",
            "0.313380\t0.387200\t1.000000\n",
            "0.302900\t0.382400\t1.000000\n",
            "0.292280\t0.375800\t1.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8jCZh1aySHF",
        "colab_type": "text"
      },
      "source": [
        "As you can see the error of the network when we test it with adversarial exampls is very high: 100% => We need to train a network which can be strong against these examples.\n",
        "Now we make the new model which has the same architecture as the previous model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eToxbl9Pp4r6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_cnn_robust = nn.Sequential(nn.Conv2d(3, 32, 3), nn.ReLU(),\n",
        "                                 nn.Conv2d(32, 32, 3, padding=1, stride=2), nn.ReLU(),\n",
        "                                 nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n",
        "                                 nn.Conv2d(64, 64, 3, padding=1, stride=2), nn.ReLU(),\n",
        "                                 Flatten(),\n",
        "                                 nn.Linear(8*8*64, 100), nn.ReLU(),\n",
        "                                 nn.Linear(100, 10)).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_j11i_nz1Sr",
        "colab_type": "text"
      },
      "source": [
        "This time we use epoch_adversarial to train the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz5IYQmJz1Bw",
        "colab_type": "code",
        "outputId": "7cd8f8c2-5f4c-4c13-d838-0157c531bcb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "opt = optim.SGD(model_cnn_robust.parameters(), lr=1e-1)\n",
        "for t in range(5):\n",
        "    train_err, train_loss = epoch_adversarial(train_loader, model_cnn_robust, opt)\n",
        "    test_err, test_loss = epoch(test_loader, model_cnn_robust)\n",
        "    adv_err, adv_loss = epoch_adversarial(test_loader, model_cnn_robust)\n",
        "    if t == 4:\n",
        "        for param_group in opt.param_groups:\n",
        "            param_group[\"lr\"] = 1e-2\n",
        "    print(*(\"{:.6f}\".format(i) for i in (train_err, test_err, adv_err)), sep=\"\\t\")\n",
        "torch.save(model_cnn_robust.state_dict(), \"model_cnn_robust.pt\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.916620\t0.900000\t0.900000\n",
            "0.905480\t0.900000\t0.900000\n",
            "0.905020\t0.900000\t0.900000\n",
            "0.901580\t0.900000\t0.900000\n",
            "0.901940\t0.900000\t0.900000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjbbJu8K5LQK",
        "colab_type": "text"
      },
      "source": [
        "As you can see, in this case the error of the model against adversarial examples is: %."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw5d4HAksrXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-bZVKzF5d8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}